{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from Functions import calc_similarity\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = os.listdir(\"./Articles\")\n",
    "corpus = []\n",
    "for i in range(len(docs)):\n",
    "    with open(\"./Articles/\" + docs[i]) as f:\n",
    "        corpus.append(f.read())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I like a bit of pow-wow in any place. Let me rephrase before you think I am eternally hankering for a fight. What I mean is I would choose crooked streets over straight highways, sweaty mayhem over pristine elegance. This is why no matter where I go in this world, coming home to India, and especially Bombay, is never dull blame growing up in the city for my pugilistic predilection. One of the many descriptors that Mark Twain used in relation to Bombay was \"pow-wow.\" The place seemed to confound him: \"Bewitching\". \"Bewildering\", \"Enchanting\", \"Arabian Nights come again?\" the man was repulsed and riveted at the same time. It was a place befitting the number of exclamations he used.\"', \"Anniversary edition have the feel of a graduation: a year of studious slogging (of which truth be told. my team and I do very little) and madcap fun which we on wish we could indulge in more) rounded off with a sense of achievement and lingering anxiety. There's pride that National Geographic Traveller india has lived to see another day and in today's precarious media landscape that should account for something. Then the gnawing question did we get it right?\", 'Our year end edition toasts ultra indulgence while travelling, featuring itineraries that many will know to be out of their financial reach. In producing these narratives, I was struck by a contrast. Travel today is dominated by minimalists or downsizers, those who preach the gospel of \"hard-knock wanderlust.\" And they almost always reap universal admiration. They are characters to aspire to, examples of made for-Instagram sayings such as, \"All you need is a backpack\" or \"#MotorcycleDiaries.\" Unable to join these gallivanting philosophers others marvel at their brave rebellion-oh, to give up the predictability of overpriced tourism traps someday, they sigh.', 'For my money, memorable disagree F ments often centre on food. A friend who was about to settle abroad was feeling particularly wistful about a storied south Bombay restaurant. the kind of eatery that locals like to call \"overrated\" and guidebook-toting tourists faithfully make a beeline for. His favourite on the menu? The baklava-a dry fruit-laden traditional sweet that smacked of decadence in every bite.']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "{'like': 80, 'bit': 14, 'pow': 111, 'wow': 170, 'place': 110, 'let': 79, 'rephrase': 125, 'think': 147, 'eternally': 43, 'hankering': 64, 'fight': 51, 'mean': 92, 'choose': 21, 'crooked': 27, 'streets': 141, 'straight': 140, 'highways': 66, 'sweaty': 144, 'mayhem': 91, 'pristine': 117, 'elegance': 39, 'matter': 90, 'world': 169, 'coming': 24, 'home': 67, 'india': 68, 'especially': 42, 'bombay': 17, 'dull': 36, 'blame': 16, 'growing': 62, 'city': 22, 'pugilistic': 119, 'predilection': 115, 'descriptors': 30, 'mark': 88, 'twain': 161, 'used': 165, 'relation': 124, 'confound': 25, 'bewitching': 13, 'bewildering': 12, 'enchanting': 40, 'arabian': 6, 'nights': 103, 'come': 23, 'man': 87, 'repulsed': 126, 'riveted': 129, 'time': 148, 'befitting': 11, 'number': 104, 'exclamations': 45, 'anniversary': 4, 'edition': 38, 'feel': 49, 'graduation': 61, 'year': 171, 'studious': 143, 'slogging': 135, 'truth': 160, 'told': 151, 'team': 146, 'little': 82, 'madcap': 85, 'fun': 56, 'wish': 167, 'indulge': 69, 'rounded': 130, 'sense': 132, 'achievement': 2, 'lingering': 81, 'anxiety': 5, 'pride': 116, 'national': 101, 'geographic': 58, 'traveller': 158, 'lived': 83, 'day': 28, 'today': 150, 'precarious': 113, 'media': 93, 'landscape': 78, 'account': 1, 'gnawing': 59, 'question': 120, 'did': 31, 'right': 128, 'end': 41, 'toasts': 149, 'ultra': 162, 'indulgence': 70, 'travelling': 159, 'featuring': 48, 'itineraries': 72, 'know': 76, 'financial': 52, 'reach': 121, 'producing': 118, 'narratives': 100, 'struck': 142, 'contrast': 26, 'travel': 157, 'dominated': 33, 'minimalists': 97, 'downsizers': 34, 'preach': 112, 'gospel': 60, 'hard': 65, 'knock': 75, 'wanderlust': 166, 'reap': 122, 'universal': 164, 'admiration': 3, 'characters': 20, 'aspire': 7, 'examples': 44, 'instagram': 71, 'sayings': 131, 'need': 102, 'backpack': 8, 'motorcyclediaries': 99, 'unable': 163, 'join': 73, 'gallivanting': 57, 'philosophers': 109, 'marvel': 89, 'brave': 18, 'rebellion': 123, 'oh': 105, 'predictability': 114, 'overpriced': 106, 'tourism': 153, 'traps': 156, 'someday': 137, 'sigh': 134, 'money': 98, 'memorable': 94, 'disagree': 32, 'ments': 95, 'centre': 19, 'food': 53, 'friend': 54, 'settle': 133, 'abroad': 0, 'feeling': 50, 'particularly': 108, 'wistful': 168, 'storied': 139, 'south': 138, 'restaurant': 127, 'kind': 74, 'eatery': 37, 'locals': 84, 'overrated': 107, 'guidebook': 63, 'toting': 152, 'tourists': 154, 'faithfully': 46, 'make': 86, 'beeline': 10, 'favourite': 47, 'menu': 96, 'baklava': 9, 'dry': 35, 'fruit': 55, 'laden': 77, 'traditional': 155, 'sweet': 145, 'smacked': 136, 'decadence': 29, 'bite': 15}\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf = vect.fit_transform(corpus)\n",
    "print(len(vect.vocabulary_))\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.01258582 0.         0.03633317]\n",
      " [0.01258582 1.         0.0449683  0.        ]\n",
      " [0.         0.0449683  1.         0.        ]\n",
      " [0.03633317 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity = ((tfidf * tfidf.T).A)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(similarity, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'article3.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking \"Article 1\" as the reference/original document for similarity calculation:\n",
    "# Document which is least similar is:\n",
    "original_doc_idx = docs.index(\"article1.txt\")\n",
    "docs[np.nanargmin(similarity[original_doc_idx])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Glove Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# Temporary file\n",
    "tmp_file = get_tmpfile('temp_word2vec.txt')\n",
    "\n",
    "# GloVe vectors loading function into temporary file\n",
    "glove2word2vec('Datasets/glove.6B.50d.txt', tmp_file)\n",
    "\n",
    "# Creating a KeyedVectors from a temporary file\n",
    "w2v_model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "print(type(w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the vocab: 400000\n",
      "Vector representation of word \"apple\"\n",
      "[ 0.52042  -0.8314    0.49961   1.2893    0.1151    0.057521 -1.3753\n",
      " -0.97313   0.18346   0.47672  -0.15112   0.35532   0.25912  -0.77857\n",
      "  0.52181   0.47695  -1.4251    0.858     0.59821  -1.0903    0.33574\n",
      " -0.60891   0.41742   0.21569  -0.07417  -0.5822   -0.4502    0.17253\n",
      "  0.16448  -0.38413   2.3283   -0.66682  -0.58181   0.74389   0.095015\n",
      " -0.47865  -0.84591   0.38704   0.23693  -1.5523    0.64802  -0.16521\n",
      " -1.4719   -0.16224   0.79857   0.97391   0.40027  -0.21912  -0.30938\n",
      "  0.26581 ]\n",
      "Length of vector for representation of each word\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in the vocab: {}\".format(len(w2v_model.vocab)))\n",
    "print(\"Vector representation of word \\\"apple\\\"\")\n",
    "print(w2v_model[\"apple\"])\n",
    "print(\"Length of vector for representation of each word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = calc_similarity(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again taking \"Article 1\" as reference for comparing other documents\n",
    "source_doc = corpus[0]\n",
    "target_docs = corpus[1:]\n",
    "\n",
    "# Calculating similarity scores:\n",
    "similarity_scores = sim.calculate_similarity(source_doc, target_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.99020684, 'doc': 'article1.txt'}\n",
      "{'score': 0.98503226, 'doc': 'article3.txt'}\n",
      "{'score': 0.9721736, 'doc': 'article2.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Just some simple code for better representation\n",
    "for dic in similarity_scores:\n",
    "    dic[\"doc\"] = docs[corpus.index(dic[\"doc\"])]\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
